{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02569b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, RandomAffine, ToTensor\n",
    "\n",
    "# Not included by default in Colab\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# For presentations purposes only (not needed in Colab)\n",
    "#plt.style.use('notebook.mplstyle')\n",
    "# Keeps the kernel from dying in notebooks on Windows machines (not needed in Colab)\n",
    "#import os\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75453ca2",
   "metadata": {},
   "source": [
    "### Download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08bd8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations\n",
    "#No agumentations (default)\n",
    "augmentations = Compose([ToTensor()])\n",
    "# Add random affine transformations\n",
    "#augmentations = Compose([RandomAffine(degrees=(-30, 30), translate=(0.1, 0.1), scale=(0.85, 1.1)), ToTensor()])\n",
    "\n",
    "# Download the MNIST dataset\n",
    "# Use datasets.MNIST for the classic numeric dataset\n",
    "# or datasets.FashionMNIST for one with clothes\n",
    "\n",
    "# Download training data.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=augmentations,\n",
    ")\n",
    "\n",
    "# Download test data.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff53cef",
   "metadata": {},
   "source": [
    "### Show an example image and illustrate that the data is pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faab5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract one example image\n",
    "example_img = training_data.data[1]\n",
    "# Use a pandas dataframe to show the whole array with pixel values colorcoded\n",
    "df = pd.DataFrame(example_img)\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430528d3",
   "metadata": {},
   "source": [
    "### Attach the data to PyTorch DataLoaders\n",
    "The dataloader will provide batches of a predefined batch size during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of images to process in one batch \n",
    "# before making a model parameter update.\n",
    "batch_size = 128\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "print('The training set contains {:d} images'.format(len(train_dataloader.dataset)))\n",
    "print('The test set contains {:d} images'.format(len(test_dataloader.dataset)))\n",
    "\n",
    "# Examplify the shape of X ad y in one batch\n",
    "print('\\nOne batch contains:')\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"  X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"  y [N]: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49425c82",
   "metadata": {},
   "source": [
    "### Define various types of networks\n",
    "We will define and compare three different networks:\n",
    "1. Simple logistic regression (a fully connected network without hidden layers).\n",
    "2. A fully connected network with two hidden layers.\n",
    "3. A convolutional neural network with five hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da762b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a logistic regression model using PyTorch\n",
    "class LogReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogReg, self).__init__()\n",
    "        self.flatten = nn.Flatten()  \n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 10),  # 28*28 --> 10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # 28x28 --> 28*28\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Define a fully connected neural network\n",
    "# with 2 hidden layers\n",
    "# and dropout for regularization\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),  # 28*28 --> 512\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 512),    # 512 --> 512\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)      # 512 --> 10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Define a deep convolutional neural network\n",
    "# and dropout for regularization\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # nn.Linear(in_features, out_features)\n",
    "        # nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, 3, 1, 1),   # 1x28x28 ==> 64x28x28\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, 3, 1, 1),  # 64x28x28 ==> 64x28x28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),             # 64x28x28 ==> 64x14x14\n",
    "            nn.Conv2d(64, 64, 3, 1, 1),  # 64x14x14 ==> 64x14x14\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, 1, 1),  # 64x14x14 ==> 64x14x14\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),             # 64x14x14 ==> 64x7x7\n",
    "            nn.Flatten(),                # 64x7x7 ==> 64*7*7\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(3136, 256),        # 64*7*7 ==> 256\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "      \n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# ---------------------------------------------------- #\n",
    "# Modern networks are usuassy build by defining smaller blocks that \n",
    "# have empirically been shown to do useful things.\n",
    "# Here is one example where we define a convolutional block with\n",
    "# residual connections from which residual networks can be built.\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    \"\"\"The Residual block of ResNet.\"\"\"\n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = nn.functional.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return nn.functional.relu(Y)\n",
    "\n",
    "# Define a deeper convolutional neural network\n",
    "# from residual blocks.\n",
    "class ResNet(nn.Module):\n",
    "    \"\"\"Buil a residual type net from multiple residual blocks\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.res_stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),    # 1x28x28 --> 32x28x28\n",
    "            nn.ReLU(),\n",
    "            Residual(32, 32),                              # 32x28x28 --> 32x28x28\n",
    "            Residual(32, 64, use_1x1conv=True, strides=2), # 32x28x28 --> 64x14x14\n",
    "            Residual(64, 64),                              # 64x14x14 --> 64x14x14\n",
    "            Residual(64, 64, use_1x1conv=True, strides=2), # 64x14x14 --> 64x7x7\n",
    "            nn.Flatten(),            # 64x7x7 --> 64*7*7\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(7*7*64, 256),  # 64*7*7 --> 256\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 10)       # 256 --> 10\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        logits = self.res_stack(X)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc634f",
   "metadata": {},
   "source": [
    "### Select the network we want to use and move it to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e82ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Select the model that we would like to use\n",
    "#model = LogReg().to(device)\n",
    "#model = MLP().to(device)\n",
    "model = ConvNet().to(device)\n",
    "#model = ResNet().to(device)\n",
    "\n",
    "# Show summary over the model and the number of parameters that it has\n",
    "print(summary(model, input_size=(batch_size, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138b7ba5",
   "metadata": {},
   "source": [
    "### Define training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae81625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, scheduler):\n",
    "    \n",
    "    # Check how many images the training set contains\n",
    "    size = len(dataloader.dataset)\n",
    "    # Certain layers (e.g. dropout) work differently during\n",
    "    # training and testing ==> use for training\n",
    "    model.train()\n",
    "    \n",
    "    # Loop over all batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        # Move the data to the GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Write out progress for 100th batch\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(f\"lr: {scheduler.get_last_lr()[0]:1.6f}\")\n",
    "\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    \n",
    "    # Check how many images the training set contains\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    # Certain layers (e.g. dropout) work differently during\n",
    "    # training and testing ==> use for testing (evaluation)\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss, correct = 0, 0\n",
    "    # Speed up computations by not computing gradients\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Loop over all batches in the test set\n",
    "        for X, y in dataloader:\n",
    "            \n",
    "            # Move the data to the GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # Compute prediction error\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            # count how many images that were classified correctly\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    # Compute and print the average loss and accuracy\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa51dcd",
   "metadata": {},
   "source": [
    "### Train the selected network\n",
    "Observe that all defined networks above have a final linear layer. The CrossEntropy loss function takes care of the softmax activation functions, as it is not neccessary to compute probabilities for selecting the most likely output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0986c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "\n",
    "# Use cross entropy loss as this is a classification task\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use Adam as our optimizer \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "# It is common to observe that performance can be improved by annealing the\n",
    "# learnign rate over time. The easiest way to achieve this is by using a \n",
    "# scheduler that adjusts it within a predefined interval.\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, \n",
    "                                                steps_per_epoch=len(train_dataloader), epochs=n_epochs, \n",
    "                                                div_factor=10, final_div_factor=100)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, scheduler)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed44cd5",
   "metadata": {},
   "source": [
    "### Make predictions for the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make one run over the whole training set \n",
    "# and store away predictions and iamges in \n",
    "# separate numpy arrays.\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "y_hat = []\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # Certain layers (e.g. dropout) work differently during\n",
    "    # training and testing ==> use for testing (evaluation)\n",
    "    model.eval()\n",
    "    \n",
    "    # Loop over the test set\n",
    "    for X_tmp, y_tmp in test_dataloader:\n",
    "        \n",
    "        # Move data to the GPU\n",
    "        X_tmp, y_tmp = X_tmp.to(device), y_tmp.to(device)\n",
    "        # Predict the label\n",
    "        pred = model(X_tmp)\n",
    "        \n",
    "        # Store all data\n",
    "        X.append(X_tmp.cpu().detach().numpy())\n",
    "        y.append(y_tmp.cpu().detach().numpy())\n",
    "        y_hat.append(pred.argmax(1).cpu().detach().numpy())\n",
    "        \n",
    "y = np.hstack(y)\n",
    "y_hat = np.hstack(y_hat)\n",
    "X = np.vstack(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0c21b",
   "metadata": {},
   "source": [
    "### Visualize example images that were incorrectly labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea276a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find incorrectly predicted images\n",
    "incorrect_idx = np.where(y != y_hat)[0]\n",
    "\n",
    "# Create a figure window\n",
    "fig = plt.figure(figsize=[17, 14])\n",
    "\n",
    "# Loop over incorrectly classified images and plot examples\n",
    "for i in range(25):\n",
    "    # Create a subplot\n",
    "    ax = fig.add_subplot(5, 5, i+1)\n",
    "    # Select an incorreclty classified image\n",
    "    idx_tmp = incorrect_idx[i]\n",
    "    # Plot the image\n",
    "    ax.imshow(X[idx_tmp, 0, :, :], cmap=cm.Greys)\n",
    "    ax.set(xticks=[], yticks=[], title='True: {:}; Pred. {:}'.format(y[idx_tmp], y_hat[idx_tmp]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
