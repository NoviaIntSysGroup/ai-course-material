{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e74f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Not included by default in Colab\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# For presentations purposes only (not needed in Colab)\n",
    "#plt.style.use('notebook.mplstyle')\n",
    "# Keeps the kernel from dying in notebooks on Windows machines (not needed in Colab)\n",
    "#import os\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd71d2a",
   "metadata": {},
   "source": [
    "### Download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4da468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93afa53",
   "metadata": {},
   "source": [
    "### Use PCA to set a baseline for further comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numpy matrices of the data to use with sklearn\n",
    "X_train = training_data.data.detach().numpy().reshape(60000, 28*28) / 255\n",
    "X_test = test_data.data.detach().numpy().reshape(10000, 28*28) / 255\n",
    "y_train = training_data.targets.detach().numpy()\n",
    "y_test = test_data.targets.detach().numpy()\n",
    "\n",
    "# Mean center\n",
    "scaler = StandardScaler(with_std=False)\n",
    "X_train_mc = scaler.fit_transform(X_train)\n",
    "X_test_mc = scaler.transform(X_test)\n",
    "\n",
    "# Fit a PCA model\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X_train_mc);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b2237",
   "metadata": {},
   "source": [
    "Next, we reconstruct the original images using various number of PCA components and compute the mean squarred error (MSE) of the reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PCA reconstruction error (MSE)')\n",
    "# Compute PCA scores for each image\n",
    "X_train_pca = X_train_mc @ pca.components_.T\n",
    "X_test_pca = X_test_mc @ pca.components_.T\n",
    "\n",
    "mse_pca_train = []\n",
    "mse_pca_test = []\n",
    "\n",
    "# Loop over the number of laten dimensions to evaluate\n",
    "n_latent_dims_pca = np.arange(10, 101, 10)\n",
    "for n_latent_dims in n_latent_dims_pca:\n",
    "\n",
    "    # Reconstruct training images\n",
    "    X_train_decoded = X_train_pca[:, :n_latent_dims] @ pca.components_[:n_latent_dims, :]\n",
    "    mse_pca_train.append( np.mean( (X_train_mc-X_train_decoded)**2 ) )\n",
    "\n",
    "    # Reconstruct test images\n",
    "    X_test_decoded = X_test_pca[:, :n_latent_dims] @ pca.components_[:n_latent_dims, :]\n",
    "    mse_pca_test.append( np.mean( (X_test_mc-X_test_decoded)**2 ) )\n",
    "\n",
    "    print('d={:d} \\t Train: {:1.4f} \\t Test: {:1.4f}'.format(n_latent_dims, mse_pca_train[-1], mse_pca_test[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb09de45",
   "metadata": {},
   "source": [
    "### Visualize what the MSE values corresponds visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fff3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure window\n",
    "fig, axs = plt.subplots(1, 10, figsize=[15, 4])\n",
    "\n",
    "# Loop over all numbers and plot an example image of each one\n",
    "for i in range(10):\n",
    "\n",
    "    # Find an image of the right number\n",
    "    idx_tmp = np.where(y_test==i)[0][0]\n",
    "    # Plot the number as an image\n",
    "    axs[i].imshow(X_test[idx_tmp, :].reshape(28, 28), cmap=cm.Greys_r)\n",
    "    axs[i].set(xticks=[], yticks=[])\n",
    "    if i == 0:\n",
    "        axs[i].set(ylabel='Original')\n",
    "\n",
    "# Create a figure window\n",
    "for n_latent_dims in [10, 30, 50, 70, 90]:\n",
    "\n",
    "    # Create a figure window\n",
    "    fig, axs = plt.subplots(1, 10, figsize=[15, 4])\n",
    "\n",
    "    # Loop over all numbers and plot an example image of each one\n",
    "    for i in range(10):\n",
    "        \n",
    "        # Find an image of the right number\n",
    "        idx_tmp = np.where(y_test==i)[0][0]\n",
    "        # Decoode\n",
    "        X_decoded_tmp = X_test_pca[idx_tmp, :n_latent_dims] @ pca.components_[:n_latent_dims, :]\n",
    "        X_decoded_tmp = scaler.inverse_transform(X_decoded_tmp.reshape(1, 28**2))\n",
    "        \n",
    "        # Plot the number as an image\n",
    "        axs[i].imshow(X_decoded_tmp.reshape(28, 28), cmap=cm.Greys_r, vmin=0, vmax=1)\n",
    "        axs[i].set(xticks=[], yticks=[])\n",
    "        if i == 0:\n",
    "            axs[i].set(ylabel='d={:d}'.format(n_latent_dims))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a984764",
   "metadata": {},
   "source": [
    "### Define a deep convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eab5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, stride=1, padding=1),  # 1x28x28 --> 64x28x28\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, 3, stride=2, padding=1), # 64x28x28 --> 64x14x14\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 32, 3, stride=2, padding=1), # 64x14x14 --> 32x7x7\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(start_dim=1),                   # 32x7x7 --> 32*7*7\n",
    "            nn.Linear(7 * 7 * 32, 256),                # 32*7*7 --> 256\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, encoded_space_dim)          # 256 --> encoded_space_dim\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, 256),                                    # encoded_space_dim --> 256\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 7 * 7 * 32),                                           # 256 --> 32*7*7\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(32, 7, 7)),                     # 32*7*7 --> 32x7x7\n",
    "            nn.ConvTranspose2d(32, 64, 3, stride=2, padding=1, output_padding=1), # 32x7x7 --> 64x14x14\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 64, 3, stride=2, padding=1, output_padding=1), # 64x14x14 --> 64x28x28\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 1, 3, stride=1, padding=1),                     # 64x28x28 --> 1x28x28\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        # Sigmoid activation function to keep the output between 0 and 1\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323dd359",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f39230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of images to process in one batch \n",
    "# before making a model parameter update.\n",
    "batch_size = 128\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# Set parameters\n",
    "n_latent_dim = 20\n",
    "\n",
    "# Initialize the model\n",
    "model = AE_ConvNet(encoded_space_dim=n_latent_dim)\n",
    "# Print the model summary\n",
    "print(summary(model, input_size=(batch_size, 1, 28, 28)))\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c252ed26",
   "metadata": {},
   "source": [
    "### Define functions for evaluating and visualizing progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, device, dataloader, loss_fn, optimizer, scheduler):\n",
    "\n",
    "    # Set model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = []\n",
    "    # Iterate the dataloader \n",
    "    for batch, (image_batch, _) in enumerate(dataloader):\n",
    "\n",
    "        size = len(dataloader.dataset)\n",
    "        \n",
    "        # Move tensor to the proper device\n",
    "        image_batch = image_batch.to(device)\n",
    "\n",
    "        # Run the model\n",
    "        decoded_data = model(image_batch)\n",
    "\n",
    "        # Evaluate loss\n",
    "        loss = loss_fn(decoded_data, image_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Detach the loss variable so we can save it\n",
    "        loss = loss.cpu().detach().numpy()\n",
    "\n",
    "        # Print batch loss\n",
    "        #print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        if batch % 50 == 0:\n",
    "            loss, current = loss.item(), batch * len(image_batch)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "        train_loss.append(loss)\n",
    "\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "# Testing function\n",
    "def test_epoch(model, device, dataloader, loss_fn):\n",
    "\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Speed up things by not computing gradients\n",
    "    with torch.no_grad():\n",
    "\n",
    "        test_loss = []\n",
    "        # Iterate the dataloader \n",
    "        for batch, (image_batch, _) in enumerate(dataloader):\n",
    "\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = image_batch.to(device)\n",
    "\n",
    "            # Run the model\n",
    "            decoded_data = model(image_batch)\n",
    "            \n",
    "            # Evaluate loss\n",
    "            loss = loss_fn(decoded_data, image_batch)\n",
    "            # Detach the loss variable so we can save it\n",
    "            loss = loss.cpu().detach().numpy()\n",
    "            test_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(test_loss)\n",
    "\n",
    "def plot_ae_outputs(model):\n",
    "    \n",
    "    plt.figure(figsize=(16, 4.5))\n",
    "    targets = test_data.targets.numpy()\n",
    "    target_idx = {i:np.where(targets==i)[0][0] for i in range(10)}\n",
    "    for i in range(10):\n",
    "        \n",
    "        img = test_data[target_idx[i]][0].unsqueeze(0).to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            rec_img = model(img)\n",
    "            \n",
    "        ax = plt.subplot(2, 10, i+1)\n",
    "        plt.imshow(img.cpu().squeeze().numpy(), cm.Greys_r, vmin=0, vmax=1)\n",
    "        ax.set(xticks=[], yticks=[]) \n",
    "        if i == 5:\n",
    "            ax.set_title('Original images')\n",
    "            \n",
    "        ax = plt.subplot(2, 10, i + 1 + 10)\n",
    "        plt.imshow(rec_img.cpu().squeeze().numpy(), cm.Greys_r, vmin=0, vmax=1)  \n",
    "        ax.set(xticks=[], yticks=[]) \n",
    "        if i == 5:\n",
    "            ax.set_title('Reconstructed images')\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d57e0",
   "metadata": {},
   "source": [
    "### Train the network\n",
    "We will train the whole network (encoder and decoder) at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4f5c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "# Use MSE to minimize the reconstruction error\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "n_epochs = 15\n",
    "# Use Adam as the default optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "# Use a scheduler to change the learnign rate over time\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=0.001, \n",
    "                                                steps_per_epoch=len(train_dataloader), epochs=n_epochs, \n",
    "                                                div_factor=10, final_div_factor=100)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    train_loss = train_epoch(model, device, train_dataloader, loss_fn, optim, scheduler)\n",
    "    test_loss = test_epoch(model, device, test_dataloader, loss_fn)\n",
    "    \n",
    "    print('\\n EPOCH {}/{} \\t train loss {} \\t test loss {}'.format(epoch + 1, n_epochs, train_loss, test_loss))\n",
    "\n",
    "    plot_ae_outputs(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616355a",
   "metadata": {},
   "source": [
    "### Test to reconstruct a random image\n",
    "Autoencoder can be used for anomaly detection if they are trained on \"normal\" data. The logic being that they are only trained to reconstruct the \"normal\" training data well, and will thus have large reconstruction errors for data that deviates from what was used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4114117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure window\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "X_rnd = np.random.rand(28, 28)\n",
    "#_rnd = np.zeros([28, 28])\n",
    "#X_rnd[:, 5:23] = 1.\n",
    "\n",
    "# Plot the input image\n",
    "X_rnd = X_rnd.reshape(1, 28, 28)\n",
    "axs[0].imshow(X_rnd[0, :, :], cmap=cm.Greys_r, vmin=0, vmax=1)\n",
    "axs[0].set(xticks=[], yticks=[], title='Input')\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "# Speed up things by not computing gradients\n",
    "with torch.no_grad():\n",
    "    test_img = torch.Tensor(X_rnd).float().unsqueeze(0)\n",
    "    decoded_img = model(test_img.to(device)).cpu().detach().numpy()\n",
    "\n",
    "# Plot the reconstructed image\n",
    "axs[1].imshow(decoded_img[0, 0, :, :], cmap=cm.Greys_r, vmin=0, vmax=1)\n",
    "axs[1].set(xticks=[], yticks=[], title='Output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
