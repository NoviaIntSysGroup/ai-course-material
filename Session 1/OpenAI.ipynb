{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21859fa5",
   "metadata": {},
   "source": [
    "### Simple OpenAI API tutorial\n",
    "Simple tutorial based on:\n",
    "https://artificialcorner.com/a-simple-guide-to-openai-api-with-python-3bb4ed9a4b0a\n",
    "\n",
    "The API requires an API key which you can generate from [here](https://platform.openai.com/account/api-keys) onse you have [signed up](https://openai.com/api/) (free of charge) to create an OpenAI account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "!pip install openai\n",
    "import openai\n",
    "\n",
    "# Used to load the API key when stored locally on your computer (not needed in Colab)\n",
    "# from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92451313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: when running on your local computer and \n",
    "# you have the the api key stored in a .env file\n",
    "# dotenv_path = find_dotenv()\n",
    "# load_dotenv(dotenv_path)\n",
    "# api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# Option 2: when running on Colab and just copy paste\n",
    "# the api key into your notebook\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82735448",
   "metadata": {},
   "source": [
    "### Text completion\n",
    "The best available model for text completion as of 1.2.2023 is text-davinci-003 (see [here](https://platform.openai.com/docs/models/gpt-3) for available models). It is the base model from which more known models such as [ChatGPT](https://openai.com/blog/chatgpt/) have been fine-tuned. Fine-tuning can be effectively used to modify the style of the response. For example, ChatGPT clearly provides more interactive and more polite responses than text-davinci-003. Fine-tuning is however done in a supervised manner, and consequently requires a dataset consisting of prompts and examples of good responses (see the [OpenAI guide](https://platform.openai.com/docs/guides/fine-tuning) for more details and [this](https://www.mlq.ai/gpt-3-fine-tuning-key-concepts/) blog post).\n",
    "\n",
    "NOTE! the text completion model as well as the other models used below all have many more arguments than what we use here. Check out the [API documenation](https://platform.openai.com/docs/api-reference/introduction) to see the full functionality offered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First test case\n",
    "prompt = \"\"\"\n",
    "Describe Ohm's law to a four year old kid\n",
    "\"\"\"\n",
    "response = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=prompt,\n",
    "              max_tokens=100, # adjusts the length of the response\n",
    "              temperature=0   # adjust the \"randonmess\" of the response\n",
    "            )\n",
    "answer = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "print(f\"You: {prompt}\")\n",
    "print(f\"OpenAI: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a822e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How easily can you get it to say bad things?\n",
    "prompt = \"\"\"\n",
    "Some people are just bad and should be separated from the rest. They could live in special camps or jails. No matter how much we want to fix them, some people are just broken. I wish we could do like they did in \n",
    "\"\"\"\n",
    "response = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=prompt,\n",
    "              max_tokens=100, # adjusts the length of the response\n",
    "              temperature=1   # adjust the \"randonmess\" of the response\n",
    "            )\n",
    "answer = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "print(f\"You: {prompt}\")\n",
    "print(f\"OpenAI: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f9279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about Swedish\n",
    "prompt = \"\"\"\n",
    "Vem var Gustav Wasa?\n",
    "\"\"\"\n",
    "response = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=prompt,\n",
    "              max_tokens=300,\n",
    "              temperature=0\n",
    "            )\n",
    "answer = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "print(f\"You: {prompt}\")\n",
    "print(f\"OpenAI: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10131276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see how much the model \"knows\"\n",
    "prompt = \"\"\"\n",
    "Who is Tomas Häyry? \n",
    "\"\"\"\n",
    "response = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=prompt,\n",
    "              max_tokens=200,\n",
    "              temperature=0\n",
    "            )\n",
    "answer = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "print(f\"You: {prompt}\")\n",
    "print(f\"OpenAI: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347021ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to introduce new information via prompt engineering\n",
    "# Let's add info from wikipedia in this case https://fi.wikipedia.org/wiki/Tomas_H%C3%A4yry\n",
    "prompt = \"\"\"\n",
    "Tomas Häyry (lokakuuta 1967) on Vaasan kaupunginjohtaja. Vaasan kaupunginvaltuuston valitessa kaupunginjohtajan elokuussa 2011 hän sai 34 ääntä 51:stä. Hän oli toiminut kaupunginjohtajan sijaisena edelliskeväästä saakka. Tätä ennen hän oli toiminut kaupungin teknisen toimen johtajana, kehitysjohtajana sekä kaupunkisuunnittelun lakimiehenä. Hän on Vaasanseudun Kehitys Oy VASEKin puheenjohtaja.\n",
    "\n",
    "Who is Tomas Häyry? \n",
    "\"\"\"\n",
    "response = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=prompt,\n",
    "              max_tokens=200,\n",
    "              temperature=0\n",
    "            )\n",
    "answer = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "print(f\"You: {prompt}\")\n",
    "print(f\"OpenAI: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to introduce false information\n",
    "prompt = \"\"\"\n",
    "My kid says that spiders have five legs. Everyone knows that spiders have five legs because god created spiders to have only five legs.\n",
    "\n",
    "Interestingly, this strange morphology where spiders have two legs on each side and one underneath the belly has been preserved during millions of years of evolution. However, the evolutionary benefit of having five legs is still being debated. \n",
    "\n",
    "How many legs does a spider have?\n",
    "\"\"\"\n",
    "response = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=prompt,\n",
    "              max_tokens=200,\n",
    "              temperature=0\n",
    "            )\n",
    "answer = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "print(f\"You: {prompt}\")\n",
    "print(f\"OpenAI: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03efcb6c",
   "metadata": {},
   "source": [
    "### Code completion\n",
    "Just as the text-davinci-003 model is trained to generate text, other models have been trained for different purposes, such as generating code. The best available model for code completion as of 1.2.2023 is code-davinci-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331255e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple test-case to generate some python code\n",
    "prompt=\"\\\"\\\"\\\"\\nMake a script that initialize a Pandas dataframe with zeros for holding 10 latitude and longitude coordinates\\n\\\"\\\"\\\"\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=prompt,\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    ")\n",
    "\n",
    "answer = response[\"choices\"][0][\"text\"]\n",
    "\n",
    "print(f\"You: {prompt}\")\n",
    "print(f\"OpenAI: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df230c34",
   "metadata": {},
   "source": [
    "### Generate images with DALL-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2bba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Expressive intelligent systems logo inspired by robotics and a beatiful scenic landscape\"\n",
    "\n",
    "response = openai.Image.create(\n",
    "  prompt=prompt,\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")\n",
    "\n",
    "image_url = response['data'][0]['url']\n",
    "print(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685d1bfe",
   "metadata": {},
   "source": [
    "### Editing images with DALL-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d783ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Download an image\n",
    "img_rgb = Image.open(requests.get(\"https://free-images.com/lg/f925/sunset_on_victoria_lake.jpg\", stream=True).raw)\n",
    "\n",
    "# Make it 512 by 512 pixels (required by the OpenAI API)\n",
    "max_size = 512\n",
    "scaling = [s/max_size for s in img_rgb.size]\n",
    "new_size = [int(s/min(scaling)) for s in img_rgb.size]\n",
    "img_rgb = img_rgb.resize(new_size)\n",
    "img_rgb = img_rgb.crop((0, 0, max_size, max_size))\n",
    "\n",
    "# save it temporarily\n",
    "img_rgb.save('img_tmp.png')\n",
    "img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mask highlighting the region we want to modify\n",
    "img_a = Image.new(\"L\", img_rgb.size, 255)\n",
    "draw = ImageDraw.Draw(img_a)\n",
    "draw.ellipse((250, 50, 450, 200), fill=0)\n",
    "\n",
    "img_rgba = img_rgb.copy()\n",
    "img_rgba.putalpha(img_a)\n",
    "img_rgba.save('mask_tmp.png')\n",
    "img_rgba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a prompt that explains the existing image as well as what we want to add to it\n",
    "response = openai.Image.create_edit(\n",
    "  image=open(\"img_tmp.png\", \"rb\"),\n",
    "  mask=open(\"mask_tmp.png\", \"rb\"),\n",
    "  prompt=\"A sunset over the ocean with a dark landmass in the background and a dark airplane in the sky\",\n",
    "  n=1,\n",
    "  size=\"512x512\"\n",
    ")\n",
    "image_url = response['data'][0]['url']\n",
    "print(image_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
